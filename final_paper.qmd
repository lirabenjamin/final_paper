---
title: "Final Project"
format: html
editor: visual
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

# Abstract

Reference bias refers to a bias in questionnaire response in which people self-report different answers depending on who they are comparing against. This is a proposed investigation to apply network and spatial analyses to a longitudinal sample of adolescents who completed questionnaires on academic self-control. One thousand and one hundred students completed questionnaires, and also nominated who their close friends were and who they thought exemplified self-control (henceforth referred to as exemplars). We show network descriptives and centrality measures, test for social autocorrelation as a function of time, and for the correlation between the friendship and the exemplar network over time.

# Introduction

People use different implicit reference points to judge their behavior when responding to questionnaire items---a systematic error known as reference bias [@lira2022]. Take John and Mary, for example, who both see the same questionnaire item asking them whether or not they usually come to class prepared. To answer such a question, they must remember when they came prepared or unprepared to class; arrow leading from own trait behavior to own trait self-report), and integrate them into a summary judgment by comparing that against their reference points for preparedness (arrow leading from reference points to own trait self-report). John has lower reference points for preparedness, and therefore thinks that bringing a notebook and a pen counts as being prepared. Mary, on the other hand, has higher reference points for preparedness, and thinks that she is *unprepared* unless she has completed homework, studied the assigned readings, and reviewed last class's material. The higher the reference point, the lower the individual will report preparedness (indicated by the negative sign). Thus, even if John and Mary usually *behave* in the same way, they will judge that same behavior differently, resulting in divergent responses.These diverse reference points might be influenced by the characteristics of the peers surrounding John and Mary. Likely, Mary thinks about preparedness this way because she is surrounded by other people who tend to prepare more than the people John is surrounded by (arrows leading from role model trait behavior and friend trait behavior to reference points), as would be suggested by research on peer descriptive norms [@cialdini2007].

```{r}
knitr::include_graphics("Theoretical Model.pdf")
```

Why reference bias matters? Questionnaires are, by far, the most widely used method for gathering data in the social sciences and in policymaking. Especially in educational contexts there is growing interest in measuring, evaluating, and hopefully improving the effectiveness of schools at developing self-regulation in their students. Some school districts have already started implementing questionnaire measures of self-regulation in an attempt to try to improve it. The intention is not misguided: there is ample evidence that self-regulation predicts an array of positive life outcomes [@moffitt2011; @almlund2011]. However, if students refer to different standards, comparisons between schools could be biased because in essence students are not answering the same questions. Thus, there is worry about "whether we can make \[self-regulation skills\] visible, comparable, and therefore amenable to deliberate policy action in a similar way that traditional tests do with academic knowledge and skills" [@oecd2021].

There is little known about reference bias. Most research comes from evaluations of charter schools that show paradoxical effects: they do not raise self-regulation self-reports, but their students are more likely to attend school, graduate, less likely to become pregnant or incarcerated, among other positive indicators [@west2016; @dobbie2013]. This has been interpreted as schools raising self-regulation (as per the objective outcomes), but differences in school norms and culture resulting in incomparable self-report measurment (i.e., reference bias). Other research relies in cross cultural comparisons, where japanese people tend to rate themselves low in conscientiousness [@m√µttus2012], despite cultural experts agreeing in japanese cultural conscientiousness [@heine2002], and objective proxies for conscientiousness affirming this too [@heine2008].

We recently directly identified reference bias by capitalizing on peer variation within a school, and thus obviating concerns about charter schools being ineffective, or cross cultural research being biased by invalid proxies or faulty perceptions of cultural judges [@lira2022]. We defined peers as students in the same school across different cohorts, or students sharing core classes. However, with the data we had we weren't able to more specifically ask the question of "Who is the referent in reference bias"? Do standards come from friends, perceptions of exemplarity, popularity, etc.

# Methods

For this project we will (1) show network descriptives and centrality measures, (2) test for social autocorrelation as a function of time, and (3) for the correlation between the friendship and the exemplar network over time.

## Descriptive and centrality

We will plot networks for friendships and exemplars and identify key actors.

## Social autocorrelation across time

We will compute Moran's I to test for social autocorrelation (outcome dependence) across each time point in the data.

## Network correlation

We have two kinds of peer nomination prompts. We will use QAP to test the correlation in this nomination patterns across time.

# Data

Data for this comes from the CDAP study (Character Development in Adolescence). It includes data from N = 1,071 (47.8% female, 50.9% male, 1.3% unreported; $M_{age}$ = 15.6; $SD_{age}$ = 13.7) students attending two public high schools in the United States who completed surveys from November 2014 to June 2016. According to school records, the race/ethnicity of our sample was: Black (49.0%), White (29.6%), Asian (14.0%), Hispanic/Latinx (4.3%), and other (3.2%). More than half (60.4%) of students were eligible for free and reduced-price meals.

Students completed virtual surveys in their school's computer laboratory and were supervised by their regular teachers. Waves of data collection were scheduled about a month before the end of each semester, and each one took around 45 minutes, scheduled during a single class period.

Students completed the Domain-Specific Impulsivity Scale \\parencite{tsukayama_domain-specific_2013}, which includes items assessing self-control (e.g., "I came to class prepared.") using a 5-point Likert-type scale ranging from 1 = *Never* to 5 = *Always*. In each wave of data collection, the observed reliability ranged from $\alpha$ = .74 to .76.

In the first wave of data collection, students nominated two classmates as friends and two classmates as self-control role models. In subsequent waves, students nominated two classmates as friends and one classmate as an self-control role model.

# Some results

## Network descriptive and centrality

We will compute centrality measures collapsing across time and nomination prompts.

```{r}
#| warning: false
library(tidyverse)
library(igraph)

g <- read_rds("data/graph.rds")
clean <- read_rds("Data/clean.l.rds")

get_centrality = function(graph, normalized = F, degree_mode = "in"){
  centrality <- tibble(
  name = V(graph)$name,
  closeness = closeness(graph,normalized = normalized),
  betweenness = betweenness(graph,normalized = normalized),
  eigenvector = eigen_centrality(graph,scale = normalized)$vector,
  degree = degree(graph,normalized = normalized, mode = degree_mode))
  return(centrality)
}

add_centrality_to_graph = function(centrality, graph){
  V(graph)$eigenvector <- centrality$eigenvector
  V(graph)$degree <- centrality$degree
  V(graph)$betweenness <- centrality$betweenness
  V(graph)$closeness <- centrality$closeness
  return(graph)
}

centrality = get_centrality(g)

g <- add_centrality_to_graph(centrality, g)
```

Let's plot centrality distributions

```{r}
centrality |> 
  pivot_longer(closeness:degree, names_to = "metric") |> 
  ggplot(aes(value))+
  geom_histogram()+
  facet_grid(~metric, scales = "free")
```

Now lets plot the networks across time. Change the Time, peer nomination, and variable accordingly to test different combinations.

```{r}
#| warning: false
# Function to translate igraph to networkD3
d3_igraph <-
  function(graph, gpa, selfcont) {
    V(graph)$label <- V(graph)$name
    V(graph)$name <- 1:length(V(graph))
    
    edgelist <-
      graph |> get.edgelist() |> 
      as.data.frame() |> as_tibble() |> mutate_all(as.integer) |> 
      mutate_all(function(x) {
        x - 1
      })
    
    nodes <- tibble(
      id = (get.vertex.attribute(graph, "name") |> as.integer()) - 1,
      label = get.vertex.attribute(graph, "label"),
      group = "1",
      gpa = get.vertex.attribute(graph, gpa),
      selfcont = get.vertex.attribute(graph, selfcont)
    ) |> 
      mutate(label = glue::glue("{label}\nGPA:{gpa |> round(2)}"))
    return(list(edgelist = edgelist, nodes = nodes))
  }

filter_graph <- function(graph = g,
                         type = "bf",
                         time = "T1") {
  time_ids <- which(E(graph)$time == time)
  g_r <- subgraph.edges(g, time_ids, delete.vertices = FALSE)
  type_ids <- which(E(g_r)$pn == type)
  g_r <- subgraph.edges(g_r, type_ids, delete.vertices = FALSE)
  return(g_r)
}

d3 <-
  d3_igraph(g |> filter_graph(type = "bf", time = 'T1'),
            gpa = "coregpa_T1",
            selfcont = "scw_s_T1")

networkD3::forceNetwork(
  Links = d3$edgelist,
  Nodes = d3$nodes,
  Source = "V1",
  Target = "V2",
  NodeID = "label",
  Group = "gpa",
  zoom = T,
  # colourScale = JS("d3.scaleLinear(d3.schemeCategory10);")
)
```

## Social autocorrelation

See `moran_i.r` script.

Results show a downward trend through time such that the outcome dependence of role models and friends decreases through time for self-reported (`scw_s`) and teacher rated (`avg_scw_tr`) self-control as with GPA (`coregpa`).

See results in the plot below

```{r}
knitr::include_graphics("figures/moran_i.png")
```

## Correlation between graphs (QAP)

See below that in some cases, students nominated the same person as a role model and a friend. What is the correlation between these two networks over time? We used QAP procedures to test this correlations and get estimates of the uncertainty of them. See the `correlation_nets.r` script. As shown in the plots below, the trend is also towards decline, such that exemplars and friends overlap less as time goes by.

### Correlations across time

```{r}
knitr::include_graphics("figures/correlation_line.png")
```

### Significance testing

```{r}
knitr::include_graphics("figures/correlation distributions.png")
```

# References
